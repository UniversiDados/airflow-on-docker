# Tutorial: Como Instalar e Executar Apache Airflow com Docker

## üìã O que voc√™ vai aprender

Neste tutorial, voc√™ aprender√° a configurar e executar o Apache Airflow usando Docker de forma simples e pr√°tica. O Airflow √© uma plataforma para desenvolver, agendar e monitorar workflows de dados.

## üîß Pr√©-requisitos

- Sistema operacional: Linux, macOS ou Windows (com WSL2)
- Conex√£o com internet
- Privil√©gios de administrador para instala√ß√£o

## üì¶ Passo 1: Instala√ß√£o do Docker e Docker Compose

### No Ubuntu/Debian:
```bash
# Atualize os pacotes
sudo apt update

# Instale depend√™ncias
sudo apt install apt-transport-https ca-certificates curl gnupg lsb-release

# Adicione a chave GPG oficial do Docker
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg

# Adicione o reposit√≥rio do Docker
echo "deb [arch=amd64 signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null

# Instale Docker Engine e Docker Compose
sudo apt update
sudo apt install docker-ce docker-ce-cli containerd.io docker-compose-plugin

# Adicione seu usu√°rio ao grupo docker (para n√£o precisar usar sudo)
sudo usermod -aG docker $USER
```

### No macOS:
1. Baixe o Docker Desktop em: https://www.docker.com/products/docker-desktop
2. Instale o arquivo `.dmg` baixado
3. Abra o Docker Desktop e aguarde a inicializa√ß√£o

### No Windows:
1. Instale o WSL2 (Windows Subsystem for Linux)
2. Baixe o Docker Desktop em: https://www.docker.com/products/docker-desktop
3. Instale seguindo as instru√ß√µes do instalador
4. Certifique-se de que a integra√ß√£o com WSL2 est√° habilitada

## ‚úÖ Passo 2: Verifica√ß√£o da Instala√ß√£o

Ap√≥s a instala√ß√£o, **reinicie seu terminal** (ou fa√ßa logout/login no Linux) e execute os comandos de verifica√ß√£o:

### Teste o Docker:
```bash
docker run hello-world
```
**O que esperar:** Uma mensagem de boas-vindas confirmando que o Docker est√° funcionando corretamente.

### Verifique a vers√£o do Docker Compose:
```bash
docker-compose --version
```
**O que esperar:** Algo como `docker-compose version 2.x.x`

> üí° **Dica:** Se voc√™ receber erros de permiss√£o no Linux, certifique-se de ter executado o comando `usermod` e reiniciado o terminal.

## üöÄ Passo 3: Configura√ß√£o do Apache Airflow

### 3.1 Baixe o arquivo de configura√ß√£o oficial:
```bash
curl -LfO 'https://airflow.apache.org/docs/apache-airflow/2.8.1/docker-compose.yaml'
```
**O que isso faz:** Baixa o arquivo de configura√ß√£o oficial do Airflow otimizado para Docker.

### 3.2 Crie a estrutura de diret√≥rios:
```bash
mkdir -p ./dags ./logs ./plugins ./config
echo -e "AIRFLOW_UID=$(id -u)" > .env
```
**O que isso faz:**
- `dags/`: Onde voc√™ colocar√° seus workflows (DAGs)
- `logs/`: Armazena logs do sistema
- `plugins/`: Para plugins personalizados
- `config/`: Configura√ß√µes adicionais
- `.env`: Define o ID do usu√°rio para evitar problemas de permiss√£o

## üóÑÔ∏è Passo 4: Inicializa√ß√£o do Banco de Dados

```bash
docker compose up airflow-init
```
**O que isso faz:** Configura o banco de dados interno do Airflow e cria o usu√°rio administrador.

**Aguarde at√© ver:** Uma mensagem indicando que a inicializa√ß√£o foi conclu√≠da com sucesso.

## üéØ Passo 5: Executar o Airflow

```bash
docker compose up -d --build
```

**O que isso faz:** Inicia todos os servi√ßos do Airflow em segundo plano (modo detached).

**Aguarde:** Cerca de 2-3 minutos para todos os servi√ßos inicializarem completamente.

## üåê Passo 6: Acessar a Interface Web

1. Abra seu navegador
2. Acesse: **http://localhost:8080**
3. Use as credenciais:
   - **Usu√°rio:** `airflow`
   - **Senha:** `airflow`

**O que voc√™ ver√°:** A interface principal do Airflow com exemplos de DAGs j√° carregados.

## üîç Passo 7: Verifica√ß√£o dos Servi√ßos

### Veja todos os containers em execu√ß√£o:
```bash
docker-compose ps
```
**O que esperar:** Uma lista mostrando todos os servi√ßos do Airflow rodando (webserver, scheduler, worker, etc.).

### Status esperado:
- ‚úÖ airflow-webserver (porta 8080)
- ‚úÖ airflow-scheduler 
- ‚úÖ airflow-worker
- ‚úÖ postgres (banco de dados)
- ‚úÖ redis (message broker)

## üõë Passo 8: Parar o Airflow

Quando quiser parar todos os servi√ßos:
```bash
docker-compose down
```
**O que isso faz:** Para e remove todos os containers, mas mant√©m os dados persistidos.

## üìÅ Estrutura Final do Projeto

Ap√≥s seguir todos os passos, voc√™ ter√° esta estrutura:
```
meu-projeto-airflow/
‚îú‚îÄ‚îÄ dags/                    # ‚Üê Coloque seus DAGs aqui
‚îú‚îÄ‚îÄ logs/                    # ‚Üê Logs autom√°ticos
‚îú‚îÄ‚îÄ plugins/                 # ‚Üê Plugins personalizados
‚îú‚îÄ‚îÄ config/                  # ‚Üê Configura√ß√µes extras
‚îú‚îÄ‚îÄ docker-compose.yaml      # ‚Üê Configura√ß√£o dos servi√ßos
‚îî‚îÄ‚îÄ .env                     # ‚Üê Vari√°veis de ambiente
```

## üéâ Pr√≥ximos Passos

1. **Crie seu primeiro DAG:** Coloque um arquivo Python na pasta `dags/`
2. **Explore a interface:** Navegue pelas abas DAGs, Admin, Browse
3. **Execute workflows:** Ative e execute os DAGs de exemplo
4. **Monitore logs:** Use a interface para acompanhar execu√ß√µes

## ‚ú® Configurando Conex√µes

Para que seus DAGs possam interagir com outros servi√ßos, como o Spark, voc√™ precisa configurar as conex√µes na interface do Airflow.

### Conex√£o com Spark (Local)

1.  Na interface do Airflow, v√° para **Admin -> Connections**.
2.  Clique no bot√£o `+` para adicionar uma nova conex√£o.
3.  Preencha o formul√°rio com os seguintes valores:
    -   **Connection Id**: `spark_default`
    -   **Connection Type**: `Spark`
    -   **Description**: `Conex√£o local com Spark via spark-submit`
    -   **Host**: `local[*]`
    -   **Deploy mode**: `client`
    -   **Spark binary**: `spark-submit`
4.  Os outros campos podem ser deixados com seus valores padr√£o.
5.  Clique em **Save**.

Com esta configura√ß√£o, voc√™ poder√° executar tarefas do tipo `SparkSubmitOperator` em sua m√°quina local.

## üÜò Solu√ß√£o de Problemas Comuns

### Problema: "Permission denied" no Linux
**Solu√ß√£o:**
```bash
sudo chown -R $USER:$USER ./dags ./logs ./plugins ./config
```

### Problema: Porta 8080 j√° em uso
**Solu√ß√£o:** Mude a porta no arquivo `docker-compose.yaml`:
```yaml
ports:
  - "8081:8080"  # Usa porta 8081 ao inv√©s de 8080
```

### Problema: Containers n√£o inicializam
**Solu√ß√£o:**
```bash
docker-compose down -v  # Remove volumes
docker-compose up airflow-init  # Reinicializa
docker-compose up -d
```

## üìö Comandos √öteis para o Dia a Dia

```bash
# Ver logs de um servi√ßo espec√≠fico
docker-compose logs airflow-webserver

# Reiniciar todos os servi√ßos
docker-compose restart

# Entrar no container do webserver
docker-compose exec airflow-webserver bash

# Atualizar apenas um servi√ßo
docker-compose up -d airflow-webserver
```

---

üéä **Parab√©ns!** Voc√™ agora tem o Apache Airflow rodando em Docker e est√° pronto para criar e gerenciar seus workflows de dados!
